{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rossmann Store Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast sales using store, promotion, and competitor data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store managers attended a monthly status meeting.\n",
    "CFO requested this solution during a monthly status meeting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 The Root Cause of the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CFO wants to renovate stores, so he needs a forecast of the next 6 weeks to renovate stores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Problem Owner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T21:11:23.709472Z",
     "start_time": "2020-10-26T21:11:23.498547Z"
    }
   },
   "source": [
    "CFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3 Solution Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Granularity: Forecast sales per day / store in the next 6 weeks  \n",
    "- Type of problem: Demand / sales forecast\n",
    "- Potential methods: Time Series\n",
    "- Delivery Format: Predictions accessed via cell phone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.493Z"
    }
   },
   "outputs": [],
   "source": [
    "#1.1\n",
    "from IPython.display       import Image\n",
    "from IPython.core.display  import HTML\n",
    "#1.3\n",
    "import pandas as pd\n",
    "#2.7.1\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#2.1\n",
    "import inflection\n",
    "\n",
    "#2.5\n",
    "import math\n",
    "\n",
    "#1.0\n",
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1.1 Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.498Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cross_validation( x_training, kfold, model_name, model, verbose=False ):\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "    for k in reversed( range( 1, kfold+1 ) ):\n",
    "        if verbose:\n",
    "            print( '\\nKFold Number: {}'.format( k ) )\n",
    "        # start and end date for validation \n",
    "        validation_start_date = x_training['date'].max() - datetime.timedelta( days=k*6*7)\n",
    "        validation_end_date = x_training['date'].max() - datetime.timedelta( days=(k-1)*6*7)\n",
    "\n",
    "        # filtering dataset\n",
    "        training = x_training[x_training['date'] < validation_start_date]\n",
    "        validation = x_training[(x_training['date'] >= validation_start_date) & (x_training['date'] <= validation_end_date)]\n",
    "\n",
    "        # training and validation dataset\n",
    "        # training\n",
    "        xtraining = training.drop( ['date', 'sales'], axis=1 ) \n",
    "        ytraining = training['sales']\n",
    "\n",
    "        # validation\n",
    "        xvalidation = validation.drop( ['date', 'sales'], axis=1 )\n",
    "        yvalidation = validation['sales']\n",
    "\n",
    "        # model\n",
    "        m = model.fit( xtraining, ytraining )\n",
    "\n",
    "        # prediction\n",
    "        yhat = m.predict( xvalidation )\n",
    "\n",
    "        # performance\n",
    "        m_result = ml_error( model_name, np.expm1( yvalidation ), np.expm1( yhat ) )\n",
    "\n",
    "        # store performance of each kfold iteration\n",
    "        mae_list.append(  m_result['MAE'] )\n",
    "        mape_list.append( m_result['MAPE'] )\n",
    "        rmse_list.append( m_result['RMSE'] )\n",
    "\n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "                          'MAE CV': np.round( np.mean( mae_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mae_list ), 2 ).astype( str ),\n",
    "                          'MAPE CV': np.round( np.mean( mape_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mape_list ), 2 ).astype( str ),\n",
    "                          'RMSE CV': np.round( np.mean( rmse_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( rmse_list ), 2 ).astype( str ) }, index=[0] )\n",
    "\n",
    "\n",
    "def mean_percentage_error( y, yhat ):\n",
    "    return np.mean( ( y - yhat ) / y )\n",
    "     \n",
    "    \n",
    "def mean_absolute_percentage_error( y, yhat ):\n",
    "    return np.mean( np.abs( ( y - yhat ) / y ) )\n",
    "\n",
    "    \n",
    "def ml_error( model_name, y, yhat ):\n",
    "    mae = mean_absolute_error( y, yhat )\n",
    "    mape = mean_absolute_percentage_error( y, yhat )\n",
    "    rmse = np.sqrt( mean_squared_error( y, yhat ) )\n",
    "    \n",
    "    return pd.DataFrame( { 'Model Name': model_name, \n",
    "                           'MAE': mae, \n",
    "                           'MAPE': mape,\n",
    "                           'RMSE': rmse }, index=[0] )\n",
    "\n",
    "def cramer_v( x, y ):\n",
    "    cm = pd.crosstab( x, y ).as_matrix()\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "    \n",
    "    chi2 = ss.chi2_contingency( cm )[0]\n",
    "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
    "    \n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    \n",
    "    return np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) )\n",
    "\n",
    "\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.501Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
    "\n",
    "Id - an Id that represents a (Store, Date) duple within the test set  \n",
    "Store - a unique Id for each store  \n",
    "Sales - the turnover for any given day (this is what you are predicting)  \n",
    "Customers - the number of customers on a given day  \n",
    "Open - an indicator for whether the store was open: 0 = closed, 1 = open  \n",
    "StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None  \n",
    "SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools  \n",
    "StoreType - differentiates between 4 different store models: a, b, c, d  \n",
    "Assortment - describes an assortment level: a = basic, b = extra, c = extended  \n",
    "CompetitionDistance - distance in meters to the nearest competitor store  \n",
    "CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened  \n",
    "Promo - indicates whether a store is running a promo on that day  \n",
    "Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating  \n",
    "Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2  \n",
    "PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.508Z"
    }
   },
   "outputs": [],
   "source": [
    "#read the entire dataset in one go to memory\n",
    "df_sales_raw = pd.read_csv('data/train.csv', low_memory = False)\n",
    "df_store_raw = pd.read_csv('data/store.csv', low_memory = False)\n",
    "\n",
    "#merge\n",
    "df_raw = pd.merge(df_sales_raw, df_store_raw, how = 'left', on = 'Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.513Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.517Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_old = list( df2.columns )\n",
    "\n",
    "snakecase = lambda x: inflection.underscore( x ) \n",
    "\n",
    "cols_new = list( map( snakecase, cols_old ) )\n",
    "\n",
    "#rename columns\n",
    "df2.columns = cols_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.521Z"
    }
   },
   "outputs": [],
   "source": [
    "print( 'Number of rows: {}'.format( df2.shape[0] ) )\n",
    "print( 'Number of columns: {}'.format( df2.shape[1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Checking Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.524Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert object to Datetime\n",
    "df2[ 'date' ] = pd.to_datetime( df2[ 'date' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.528Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.532Z"
    }
   },
   "outputs": [],
   "source": [
    "#number of missing values per column\n",
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.535Z"
    }
   },
   "outputs": [],
   "source": [
    "#colocar as 3 formas de resolver NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.539Z"
    }
   },
   "outputs": [],
   "source": [
    "#percentage of missing values\n",
    "( df2.isna().sum() / df2.shape[0] ).sort_values(ascending = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.542Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.546Z"
    }
   },
   "outputs": [],
   "source": [
    "#promo_interval    \n",
    "month_map = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "df2['promo_interval'].fillna(0, inplace = True)\n",
    "df2['month_map'] = df2['date'].dt.month.map( month_map )\n",
    "df2['is_promo'] = df2[['promo_interval', 'month_map']].apply(lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split(',') else 0, axis = 1)\n",
    "\n",
    "#promo2_since_week   \n",
    "df2[ 'promo2_since_week' ] = df2.apply( lambda x: x[ 'date' ].week if math.isnan( x[ 'promo2_since_week' ] ) else x[ 'promo2_since_week' ],  axis = 1 )\n",
    "\n",
    "#promo2_since_year     \n",
    "df2[ 'promo2_since_year' ] = df2.apply( lambda x: x[ 'date' ].year if math.isnan( x[ 'promo2_since_year' ] ) else x[ 'promo2_since_year' ],  axis = 1 )\n",
    "\n",
    "#competition_open_since_year \n",
    "df2[ 'competition_open_since_year' ] = df2.apply( lambda x: x[ 'date' ].year if math.isnan( x[ 'competition_open_since_year' ] ) else x[ 'competition_open_since_year' ],  axis = 1 )\n",
    "\n",
    "#competition_open_since_month: Store has no nearest competitor or Store has the next competitor but does not know when it opened\n",
    "df2[ 'competition_open_since_month' ] = df2.apply( lambda x: x[ 'date' ].month if math.isnan( x[ 'competition_open_since_month' ] ) else x[ 'competition_open_since_month' ],  axis = 1 )\n",
    "\n",
    "#competition_distance: as it is empty, it must be assumed that there is no competitor nearby or he is too far away\n",
    "df2[ 'competition_distance' ] = df2[ 'competition_distance' ].apply( lambda x:  200000  if math.isnan( x ) else x )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.551Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.554Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Change Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.558Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[ 'competition_open_since_month' ] = df2[ 'competition_open_since_month' ].astype( 'int32' )\n",
    "df2[ 'competition_open_since_year' ] = df2[ 'competition_open_since_year' ].astype( 'int32' )\n",
    "df2[ 'promo2_since_week' ] = df2[ 'promo2_since_week' ].astype( 'int32' )\n",
    "df2[ 'promo2_since_year' ] = df2[ 'promo2_since_year' ].astype( 'int32' )\n",
    "\n",
    "# convert object to Datetime\n",
    "df2[ 'date' ] = pd.to_datetime( df2[ 'date' ] )\n",
    "\n",
    "# in order to optimize memory, the allocation space must be reduced\n",
    "df2 = df2.astype( { col: 'int32' for col in df2.select_dtypes( 'int64' ).columns } )\n",
    "df2 = df2.astype( { col: 'float32' for col in df2.select_dtypes( 'float64' ).columns } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.563Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T18:26:04.390196Z",
     "start_time": "2020-10-29T18:26:04.386200Z"
    }
   },
   "source": [
    "## 2.7 Descriptive Statistical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.568Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.573Z"
    }
   },
   "outputs": [],
   "source": [
    "num_atributes = df2.select_dtypes(include = ['int32', 'float32'])\n",
    "cat_atributes = df2.select_dtypes(exclude = ['int32', 'float32', 'datetime64[ns]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T18:31:51.951935Z",
     "start_time": "2020-10-29T18:31:51.948937Z"
    }
   },
   "source": [
    "### 2.7.1 Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.576Z"
    }
   },
   "outputs": [],
   "source": [
    "# Central tendency - median, mean\n",
    "ct1 = pd.DataFrame(num_atributes.apply(np.mean)).T\n",
    "ct2 = pd.DataFrame(num_atributes.apply(np.median)).T\n",
    "# Dispersion - std, min, max, range, skew, curtosis\n",
    "d1 = pd.DataFrame( num_atributes.apply( np.std ) ).T\n",
    "d2 = pd.DataFrame( num_atributes.apply( min ) ).T\n",
    "d3 = pd.DataFrame( num_atributes.apply( max ) ).T\n",
    "d4 = pd.DataFrame( num_atributes.apply( lambda x: x.max() - x.min() ) ).T\n",
    "d5 = pd.DataFrame( num_atributes.apply( lambda x: x.skew() ) ).T\n",
    "d6 = pd.DataFrame( num_atributes.apply( lambda x: x.kurtosis() ) ).T\n",
    "\n",
    "d7 = pd.DataFrame(num_atributes.quantile(.25)).T\n",
    "d8 = pd.DataFrame(num_atributes.quantile(.50)).T\n",
    "d9 = pd.DataFrame(num_atributes.quantile(.75)).T\n",
    "\n",
    "\n",
    "# concatenate\n",
    "m = pd.concat( [d2, d7, d8, d9, d3, d4, ct1, ct2, d1, d5, d6 ] ).T.reset_index()\n",
    "m.columns = ['Atributes','Min','25%','50%','75%', 'Max','Range','Mean','Median','Std', 'Skew', 'Kurtosis']\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#sales = media e mediana proximas (skew proxima de 0 logo eh proxima de normal, kurtosis = 1 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.580Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(df2['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.585Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(df2['competition_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.588Z"
    }
   },
   "outputs": [],
   "source": [
    "#using Pandas Describe\n",
    "num_atributes.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.2 Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.593Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_atributes.apply(lambda x: x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.596Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_atributes.nunique().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.600Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_atributes.describe(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.603Z"
    }
   },
   "outputs": [],
   "source": [
    "aux = df2[(df2['state_holiday'] != '0') & (df2['sales'] > 0)]\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.boxplot( x='state_holiday', y='sales', data=aux )\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.boxplot( x='store_type', y='sales', data=aux )\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.boxplot( x='assortment', y='sales', data=aux )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Save Dataset Clean - Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.608Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.to_csv('data/02_Rossmann_Clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.612Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Hypothesis Mind Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.617Z"
    }
   },
   "outputs": [],
   "source": [
    "Image ('img/MindMapHypothesis.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Hypothesis List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T18:57:25.031066Z",
     "start_time": "2020-11-10T18:57:25.023071Z"
    }
   },
   "source": [
    "**1.** Stores with a larger assortment should sell more.\n",
    "\n",
    "**2.** Stores with closer competitors should sell less.\n",
    "\n",
    "**3.** Stores with longer competitors should sell more.\n",
    "\n",
    "**4.** Stores with active promotions for longer should sell more.\n",
    "\n",
    "**5.** Stores with more promotion days should sell more.\n",
    "\n",
    "**6.** Stores with more consecutive promotions should sell more.\n",
    "\n",
    "**7.** Stores open during the Christmas holiday should sell more.\n",
    "\n",
    "**8.** Stores should sell more over the years.\n",
    "\n",
    "**9.** Stores should sell more in the second half of the year.\n",
    "\n",
    "**10.** Stores should sell more after the 10th of each month.\n",
    "\n",
    "**11.** Stores should sell less on weekends.\n",
    "\n",
    "**12.** Stores should sell less during school holidays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.621Z"
    }
   },
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.626Z"
    }
   },
   "outputs": [],
   "source": [
    "#year\n",
    "df3[ 'year' ] = df3[ 'date' ].dt.year\n",
    "\n",
    "#month\n",
    "df3[ 'month' ] = df3[ 'date' ].dt.month\n",
    "\n",
    "#day\n",
    "df3[ 'day' ] = df3[ 'date' ].dt.day\n",
    "\n",
    "#weak of year\n",
    "df3[ 'week_of_year' ] = df3[ 'date' ].dt.weekofyear\n",
    "\n",
    "#year week\n",
    "df3[ 'year_week' ] = df3[ 'date' ].dt.strftime( '%Y-%W')\n",
    "\n",
    "#competition since\n",
    "df3[ 'competition_since' ] = df3.apply(lambda x: datetime.datetime(year = x[ 'competition_open_since_year' ] , month = x[ 'competition_open_since_month' ], day = 1), axis = 1)\n",
    "df3['competition_time_month'] = ( ( df3[ 'date' ] - df3[ 'competition_since' ] ) / 30).apply( lambda x: x.days ).astype( 'int32' )\n",
    "\n",
    "#promo since\n",
    "df3['promo_since'] = df3['promo2_since_year'].astype( str ) + '-' + df3['promo2_since_week'].astype( str )\n",
    "df3['promo_since'] = df3['promo_since'].apply( lambda x:  datetime.datetime.strptime( x + '-1', '%Y-%W-%w') - datetime.timedelta( days = 7 ) )\n",
    "df3['promo_time_week'] = ( ( df3[ 'date' ] - df3[ 'promo_since' ] ) / 7).apply( lambda x: x.days ).astype( 'int32' )\n",
    "\n",
    "#assortment\n",
    "df3['assortment'] = df3['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended')\n",
    "\n",
    "#state_holiday\n",
    "df3['state_holiday'] = df3['state_holiday'].apply(lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas'  if x == 'c' else 'regular_day')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.629Z"
    }
   },
   "outputs": [],
   "source": [
    "df3.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Save Dataset - Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.634Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.to_csv('data/03_Rossmann.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0. Filtering Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.637Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Line Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.641Z"
    }
   },
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.645Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df4[(df4['open'] != 0) & (df4['sales'] > 0)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Column Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:43:22.649Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df4.drop(['customers', 'open', 'promo_interval', 'month_map'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Save Dataset - Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T21:46:19.883Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.to_csv('data/04_Rossmann.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Indice",
   "title_sidebar": "Indice",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
